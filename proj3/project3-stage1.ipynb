{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Transformer BoolQ\n",
    "\n",
    "The documentation is split into small chunks following the suggestion in class and from feedback for previous projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Classification of BoolQ with Transformers.\n",
    "\n",
    "\n",
    "W&B Link: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Preliminary steps for setting getting the project running.\n",
    "\n",
    "## Tools used\n",
    "- GPUHub JupyterLab\n",
    "- Pytorch Lightning documentation\n",
    "- No AI tools used, as they do not help with reading API documentation and GitHub issues \n",
    "- Previous projects documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "The notebook was created with:\n",
    "Python \n",
    "\n",
    "Install all necessary dependencies\n",
    "- PyTorch: `torch lightning`\n",
    "- Hugging Face: `huggingface_hub datasets`\n",
    "- Weights & Biases: `wandb`\n",
    "- nltk: `nltk`\n",
    "- numpy: `numpy`\n",
    "- scikit-learn: `scikit-learn`\n",
    "- Lint and Formatting: `ruff`\n",
    "\n",
    "Versions of dependencies are pinned for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook setup\n",
    "Import all necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log into Hugging Face and Weights & Biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Predefined requirements:\n",
    "- Download the BoolQ dataset with `datasets` and split it in the predefined way.\n",
    "- Train / Validation / Test split\n",
    "\n",
    "Used features:\n",
    "- `question` and `passage` as word vectors\n",
    "- `answer` as label\n",
    "\n",
    "Input format:\n",
    "- concatenated `question` and `passage` word vectors\n",
    "- with a special seperator token in the middle to differentiate between them\n",
    "- the ordering should not matter as transformers do not have sequential processing like RNNs\n",
    "\n",
    "Label format:\n",
    "- convert `answer` boolean to 1 or 0\n",
    "- Model output is probability of 1\n",
    "- `dataset.cast_column(\"answer\", Value(\"int32\"))`\n",
    "\n",
    "Batch size: 64 for faster training than with individual samples\n",
    "\n",
    "Why not:\n",
    "- Stemming/ Lemmatization\n",
    "    - Removes potential information about how the word is used. Which is important for answering questions.\n",
    "- Removal of other words/ stopwords\n",
    "    - Stopwords are important to answering the question, as negations and other important words are counted as stopwords.\n",
    "    - Some words might be worth removing (wikipedia parsing errors, tooltip text in paragraph), but the required effort for minimal gains are not work.\n",
    "- Format cleaning\n",
    "    - Other than removing non ascii words there no cleaning is needed.\n",
    "    - Because looking through some examples of the data it reads like the intended text.\n",
    "- Truncation\n",
    "    - As discussed in class: information will be lost. As input sizes are not a problem, this is not needed.\n",
    "- Padding\n",
    "    - As discussed in class: Padding will be done for each batch indivdually, instead of padding all passages to the same length.\n",
    "\n",
    "\n",
    "## Correctness tests\n",
    "- Check processed passages and questions before embedding if they still make sense \n",
    "- Check embedding lengths\n",
    "\n",
    "## Implementation\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and split dataset in predefined way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lower case text\n",
    "    - Case of words is not very important for answering questions, has potential to reduce vocabulary size\n",
    "    - question is also only lowercased, therefore lowercasing the passage brings them closer together in terms of format\n",
    "    - With `.lower()`\n",
    "- Remove special characters (punctuation)\n",
    "    - Punctuation is not relevant for answering questions. Question marks are implicit for the question. Passage does not contain important punctuation\n",
    "    - Could reduce the needed context for a sentence, improving the performance of the model\n",
    "    - Remove by checking against `string.punctuation` \n",
    "- Tokenize sentence with `nltk`\n",
    "    - Use `punkt_tokenize` as we are interested in every word\n",
    "    - Instead of `word_tokenize` as the tokenization was not very good in the last projects\n",
    "- Remove words with non ascii (phoenetics etc.)\n",
    "    - Non ascii words are not as important for answering questions, as there are not enough of them to be relevant\n",
    "    - Example: `Persian (/ˈpɜːrʒən, -ʃən/)` only the first part is important\n",
    "    - Remove non ascii by checking `.isascii()`\n",
    "- Concat `question` and `passage` into `query`\n",
    "    - The Transformers implementation will only work on one sequence and not multiple \n",
    "    - Add special seperator token between them to distinguish both texts from another\n",
    "\n",
    "Check processed passages and questions if they still make sense. The question must still be answerable with the passage even after the processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unnecssary `question` and `passage` columns, as they are represented in `query`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert answer boolean to 1 or 0, because the model output is a probability of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate vocabulary for embedding layer.\n",
    "- Use all words present, to not lose information\n",
    "- Introduce special tokens for padding and seperation\n",
    "- `torchtext.vocab.build_vocab_from_iterator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "Predefined requirements:\n",
    "- nn.Embedding\n",
    "- nn.TransformerEncoder\n",
    "    - 6-layers randomly initialized\n",
    "- Classifier\n",
    "    - 2 Layers\n",
    "    - ReLu\n",
    "\n",
    "## Network Architecture\n",
    "- Input layer\n",
    "    - `nn.Embedding`\n",
    "    - Input Dimension: Vocabulary size\n",
    "    - Output Dimension: Embedding Dimension\n",
    "    - Intialized with random weights\n",
    "    - Embedding Dimension: 256\n",
    "- Positional Encoding\n",
    "    - `RotaryPositionalEmbeddings` or `PositionalEncoding`\n",
    "    - As transformers does not have positional information, this has to be added the input\n",
    "    - Absolute is used as a baseline\n",
    "    - Rotary is used instead of absolute or relatve as it combines the best of both\n",
    "- Hidden layers\n",
    "    - `nn.TransformerEncoder`\n",
    "    - Input Dimension: Embedding Dimension\n",
    "    - Output Dimension: Embedding Dimension\n",
    "    - No input masking will be done, as that could obscure important information for the task\n",
    "- Output layer\n",
    "    - `nn.Linear`\n",
    "    - Input Dimension: Embedding Dimension\n",
    "    - Output Dimension: 1\n",
    "        - Output is probability of class (1 = 100% true, 0 = 0% true)\n",
    "    - Activation: `torch.nn.ReLu`\n",
    "    - Final Activation: `torch.sigmoid`\n",
    "\n",
    "- Normalization: Done in `TransformerEncoder` with `LayerNorm`\n",
    "    - It seems that `BatchNorm` is not optimal for transformers [source](https://stats.stackexchange.com/questions/474440/why-do-transformers-use-layer-norm-instead-of-batch-norm)\n",
    "- Regularization: done by optimizer\n",
    "\n",
    "\n",
    "### Loss function\n",
    "Binary Cross-Entropy: \n",
    "- Is used because it is the best choice for binary classification problems\n",
    "- `torch.nn.BCELoss`\n",
    "\n",
    "### Optimizer\n",
    "AdamW:\n",
    "- Chosen because it should be better with less hyperparamater tuning than SGD and the default Adam\n",
    "- `torch.optim.AdamW`\n",
    "\n",
    "## Correctness test\n",
    "Test run of training, validation, test and prediction with 1 input\n",
    "\n",
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correctness test of the model definition, by running the model with one batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoints\n",
    "Best epochs based on smallest validation loss:\n",
    "- Uses loss because it is the most important metric for the model\n",
    "- Save few checkpoints (top 3) to not bloat the storage, because previous project managed to fill wandb storage with too many checkpoints\n",
    "- uploaded to wandb for later use\n",
    "- `ModelCheckpoint`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "- Positional Encoding (Absolute, Rotary)\n",
    "    - To check if rotary is better than absolute\n",
    "- Number of attention heads (4, 6, 8)\n",
    "    - To check if more or less attention heads are needed\n",
    "- Learning rate (1e-3, 1e-4, 1e-5)\n",
    "    - To check which learning rate is optimal\n",
    "    - No learning rate scheduler is needed as AdamW handles adjusting learning rates dynamically on its own with the passed learning rate being the maximum\n",
    "\n",
    "\n",
    "### Early stop\n",
    "Compare to previous epochs validation accuracy\n",
    "- wandb sweeps use the Hyperband algorithm\n",
    "- Max epochs 60\n",
    "- Check every 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Metrics for training and validation:\n",
    "- Accuracy, because we are interested in both correct true and false predictions\n",
    "- Loss, to see how confident the model is in its predictions\n",
    "\n",
    "Loss is the main metric for all decisions, as it is the most important metric for the model. Accuracy should follow loss in a correct model. Therefore, it is not necessary to optimize for accuracy.\n",
    "\n",
    "As discussed in class no other metrics are needed for training and validation. As accuracy and loss are sufficient to evaluate which model is the best.\n",
    "\n",
    "Log training and validation metrics to wandb after every epoch. Logging per step would be too noisy and have no benefit.\n",
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run validation after every epoch (done automatically by pytorch lightning)\n",
    "- To check how the model is doing on unseen data\n",
    "- Also needed to be able to create model checkpoints and early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the train and validation was defined correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `DataLoader` with `collate_fn` to create batches with the defined padding token to maximum length of concatenated question and passage for each batch\n",
    "- As this was suggested to be done in class instead of padding all inputs to the same length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use `wandb.sweep` for hyperparameter tuning.\n",
    "    - Grid search will be used, as the hyperparameter choices are discrete and the search space is not too large (3x3x3 = 27 experiments)\n",
    "    - Manually doing various experiments is tedious therefore use automated sweeps\n",
    "    - Best integration into wandb instead of other libraries such as optuna, ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all experiments have run select best runs based on the smallest loss as the final model to be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "A few additional metrics are implemented for evaluation for better interpretation of the model results.\n",
    "\n",
    "Metrics:\n",
    "- Accuracy\n",
    "    - to be able to compare the model to the previous projects\n",
    "    - As well as to check how it compares to the dataset imbalance\n",
    "    - `torchmetrics.functional.classification.accuracy(preds, target, task='binary')`\n",
    "- Confusion matrix\n",
    "    - To be able to see where the model tends to make mistakes.\n",
    "    - `torchmetrics.functional.confusion_matrix(preds, target, num_classes=2)`\n",
    "    - As discussed in class: use scikit-learn instead of wandb, as it is easier to interpret\n",
    "- Recall and Specifcity\n",
    "    - For error anlysis of the predictions of the classes\n",
    "    - Suggested in class to see how the model performs on the different classes\n",
    "    - Recall for true labels, specificity for false lables\n",
    "    - `torchmetrics.functional.recall(preds, target, task='binary')`\n",
    "    - `torchmetrics.functional.specificity(preds, target, task='binary')` \n",
    "\n",
    "The averaging of the metrics is the default of `micro` which means the metrics are caculated without weighting of the classes.\n",
    "\n",
    "## Implementation\n",
    "\n",
    "## Result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the implementation for test and predict are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best model from wandb artifact registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement confusion matrix calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run evaluation of final model with test and validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation\n",
    "Expectation:\n",
    "70% accuracy with test dataset. As this would be better than the test label imbalance of 62.2% true labels.\n",
    "The expectation is higher than past projects as transformers have the potential to be better than the previous methods.\n",
    "Further the expectation is that most of the accuracy comes from the majority class and not a balanced correct prediction of both classes. This is because we just select by minmum loss and not by balanced accuracy.\n",
    "The model with `RotaryPositionEmbedding` should outperform `PositionEncoding` as it is an improvement to the position encodings.\n",
    "More attention heads should also perform better than less, as the model should be able to generalize better.  \n",
    "\n",
    "## Results\n",
    "\n",
    "## Learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
